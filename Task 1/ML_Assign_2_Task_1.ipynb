{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1 Question 1\n",
    "\n",
    "Use torch.autograd to find the true gradient on the above dataset using linear regression (in the form \n",
    "$θ1x+θ0$) for any given values of $(θ0,θ1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(45)\n",
    "num_samples = 40\n",
    "    \n",
    "# Generate data\n",
    "x1 = np.random.uniform(-1, 1, num_samples)\n",
    "f_x = 3*x1 + 4\n",
    "eps = np.random.randn(num_samples)\n",
    "y = f_x + eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Gradient of θ0: -7.447053909301758\n",
      "True Gradient of θ1: -1.0253016948699951\n"
     ]
    }
   ],
   "source": [
    "# Converting data to PyTorch tensors \n",
    "x_tensor = torch.tensor(x1)\n",
    "y_tensor = torch.tensor(y)\n",
    "\n",
    "# Initializing parameters theta0 and theta1 with 0\n",
    "theta0 = torch.tensor(0, dtype=torch.float32, requires_grad=True)\n",
    "theta1 = torch.tensor(0, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "#Linear regresion functon\n",
    "def linear_regression(x, theta0, theta1):\n",
    "    return theta1 * x + theta0\n",
    "\n",
    "#the loss function (Mean Squared Error)\n",
    "def loss_function(y_pred, y):\n",
    "    return ((y_pred - y) ** 2).mean()\n",
    "\n",
    "# Forward pass: compute predictions and loss\n",
    "y_pred = linear_regression(x_tensor, theta0, theta1)\n",
    "loss = loss_function(y_pred, y_tensor)\n",
    "\n",
    "# Backward pass: compute gradients\n",
    "loss.backward()\n",
    "\n",
    "print(f\"True Gradient of θ0: {theta0.grad.item()}\")\n",
    "print(f\"True Gradient of θ1: {theta1.grad.item()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1 Question 2\n",
    "\n",
    "Using the same $(θ0,θ1)$ as above, calculate the stochastic gradient for all points in the dataset. Then, find the average of all those gradients and show that the stochastic gradient is a good estimate of the true gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-7.4470539569854735\n",
      "-1.02530176602304\n"
     ]
    }
   ],
   "source": [
    "stocastic_gradient_0 = []\n",
    "stocastic_gradient_1 = []\n",
    "stocastic_theta0 = torch.tensor(0.0, requires_grad=True)\n",
    "stocastic_theta1 = torch.tensor(0.0, requires_grad=True)\n",
    "for xi,yi in zip(x_tensor,y_tensor):\n",
    "    stocastic_theta0.grad = None\n",
    "    stocastic_theta1.grad = None\n",
    "\n",
    "    stocastic_y_pred = linear_regression(xi,stocastic_theta0,stocastic_theta1)\n",
    "    stocastic_loss = loss_function(stocastic_y_pred, yi)\n",
    "\n",
    "    stocastic_loss.backward()\n",
    "    stocastic_gradient_0.append(stocastic_theta0.grad.item())\n",
    "    stocastic_gradient_1.append(stocastic_theta1.grad.item())\n",
    "\n",
    "\n",
    "stocastic_gradient_0 = np.array(stocastic_gradient_0)\n",
    "stocastic_gradient_1 = np.array(stocastic_gradient_1)\n",
    "\n",
    "print(stocastic_gradient_0.mean())\n",
    "print(stocastic_gradient_1.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Stochastic Gradient with respect to theta_0: -7.4470539569854735\n",
      "Mean Stochastic Gradient with respect to theta_1: -1.02530176602304\n",
      "\n",
      "True Gradient with respect to theta_0: -7.447053909301758\n",
      "True Gradient with respect to theta_1: -1.0253016948699951\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Stochastic Gradient with respect to theta_0:\", stocastic_gradient_0.mean())\n",
    "print(\"Mean Stochastic Gradient with respect to theta_1:\", stocastic_gradient_1.mean())\n",
    "print()\n",
    "print(\"True Gradient with respect to theta_0:\", theta0.grad.item())\n",
    "print(\"True Gradient with respect to theta_1:\", theta1.grad.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the gradient calculated using the Stocastic gradient decent is very close to True gradient,  \n",
    "this is a proof that Stocastic gradient is good estimate of true value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
